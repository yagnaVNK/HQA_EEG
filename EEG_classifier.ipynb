{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "451b07d8",
   "metadata": {
    "papermill": {
     "duration": 0.004801,
     "end_time": "2024-01-18T12:14:52.437338",
     "exception": false,
     "start_time": "2024-01-18T12:14:52.432537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fix seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c3f0d1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T12:14:52.448931Z",
     "iopub.status.busy": "2024-01-18T12:14:52.448151Z",
     "iopub.status.idle": "2024-01-18T12:14:53.889683Z",
     "shell.execute_reply": "2024-01-18T12:14:53.888755Z"
    },
    "papermill": {
     "duration": 1.449627,
     "end_time": "2024-01-18T12:14:53.891811",
     "exception": false,
     "start_time": "2024-01-18T12:14:52.442184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed = 1996\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "torch.backends.cudnn.determenistic = True\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d470aaa",
   "metadata": {
    "papermill": {
     "duration": 0.005197,
     "end_time": "2024-01-18T12:14:53.902285",
     "exception": false,
     "start_time": "2024-01-18T12:14:53.897088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ca934e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\GitHub\\HQA_EEG\\data\\train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:34<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "ys_ = []\n",
    "\n",
    "traindir = Path('./data/train/')\n",
    "print(traindir.absolute())\n",
    "\n",
    "\n",
    "for datapath in tqdm([*sorted(traindir.glob('*_data.csv'))]):\n",
    "    eventpath = datapath.parent / ( datapath.stem[:-5] + '_events.csv' )\n",
    "    \n",
    "    \n",
    "    x = pd.read_csv(datapath)\n",
    "    y = pd.read_csv(eventpath)\n",
    "\n",
    "    x = x.iloc[:,1:].values\n",
    "    y_ = y.iloc[:,1:].values\n",
    "\n",
    "    xs.append(x.astype(np.float32))\n",
    "    ys.append(y_.astype(np.uint8))\n",
    "\n",
    "xs_train = xs[:-2]\n",
    "ys_train = ys[:-2]\n",
    "\n",
    "xs_valid = xs[-2:]\n",
    "ys_valid = ys[-2:]\n",
    "\n",
    "print(len(xs_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "566ff9d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T12:16:46.661297Z",
     "iopub.status.busy": "2024-01-18T12:16:46.660973Z",
     "iopub.status.idle": "2024-01-18T12:16:46.864075Z",
     "shell.execute_reply": "2024-01-18T12:16:46.863248Z"
    },
    "papermill": {
     "duration": 0.219365,
     "end_time": "2024-01-18T12:16:46.866253",
     "exception": false,
     "start_time": "2024-01-18T12:16:46.646888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ecgmentations as E\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, x, y, augs=dict, train=False):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.augs = augs\n",
    "        \n",
    "        self.train = train\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eeg = self.x[idx]\n",
    "        mask = self.y[idx]\n",
    "\n",
    "        if self.train:\n",
    "            length = mask.shape[0]\n",
    "\n",
    "            size = 5000\n",
    "            smask = (np.sum(mask[:-size], axis=1) > 0).astype(np.uint8)\n",
    "            smask = smask * 5 + 1\n",
    "            p = smask / smask.sum()\n",
    "\n",
    "            jdx = np.random.choice(length-size, p=p)\n",
    "\n",
    "            eeg = eeg[jdx:jdx+size]\n",
    "            mask = mask[jdx:jdx+size]\n",
    "\n",
    "        auged = self.augs(ecg=eeg, mask=mask)\n",
    "        eeg, mask = auged['ecg'], auged['mask']\n",
    "\n",
    "        return eeg.T, mask.T\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "augs = E.Sequential([\n",
    "    E.TimeCrop(length=5000, p=1.0),\n",
    "])\n",
    "\n",
    "dataset = EEGDataset(xs_train, ys_train, augs, True) \n",
    "\n",
    "train_dataloader = DataLoader(dataset, batch_size=25, num_workers=3, shuffle=True)\n",
    "\n",
    "dataset = EEGDataset(xs_train, ys_train) \n",
    "train_dataloader_ = DataLoader(dataset, batch_size=32, num_workers=3, shuffle=False)\n",
    "\n",
    "dataset = EEGDataset(xs_valid, ys_valid)\n",
    "valid_dataloader = DataLoader(dataset, batch_size=32, num_workers=3, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaae53c6",
   "metadata": {
    "papermill": {
     "duration": 0.012815,
     "end_time": "2024-01-18T12:16:46.892354",
     "exception": false,
     "start_time": "2024-01-18T12:16:46.879539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57cb9266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128210, 32)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.x[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59428f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_dataloader_:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0619784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\GitHub\\HQA_EEG\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "16\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn import metrics\n",
    "from nnspt.segmentation.unet import Unet\n",
    "\n",
    "model = Unet(in_channels=32, out_channels=6, encoder='timm-efficientnet-b1')\n",
    "model.to(device)\n",
    "print(\"9\")\n",
    "nepochs = 10\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=0.00175)\n",
    "shed = torch.optim.lr_scheduler.CosineAnnealingLR(opt, nepochs*len(train_dataloader))\n",
    "\n",
    "loss_his, train_loss = [], []\n",
    "print(\"16\")\n",
    "best_score = 0.\n",
    "best_state_dict = copy.deepcopy(model.state_dict())\n",
    "print(\"19\")\n",
    "\n",
    "for i, (eeg_batch, mask_batch) in enumerate(train_dataloader):\n",
    "    print(\"22\")\n",
    "    eeg_batch, mask_batch = eeg_batch.to(device), mask_batch.to(device)\n",
    "    print(\"24\")\n",
    "    logits = model(eeg_batch)\n",
    "    print(\"26\")\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, mask_batch.float())\n",
    "    print(\"28\")\n",
    "    loss.backward()\n",
    "    print(\"30\")\n",
    "    opt.step()\n",
    "    print(\"32\")\n",
    "    shed.step()\n",
    "    print(\"34\")\n",
    "    opt.zero_grad()\n",
    "    print(\"36\")\n",
    "    train_loss.append(loss.item())\n",
    "    print(\"38\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf77e73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T12:16:46.919474Z",
     "iopub.status.busy": "2024-01-18T12:16:46.919135Z",
     "iopub.status.idle": "2024-01-18T12:38:14.551532Z",
     "shell.execute_reply": "2024-01-18T12:38:14.550368Z"
    },
    "papermill": {
     "duration": 1287.648355,
     "end_time": "2024-01-18T12:38:14.553600",
     "exception": false,
     "start_time": "2024-01-18T12:16:46.905245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn import metrics\n",
    "from nnspt.segmentation.unet import Unet\n",
    "\n",
    "model = Unet(in_channels=32, out_channels=6, encoder='timm-efficientnet-b1')\n",
    "model.to(device)\n",
    "print(\"9\")\n",
    "nepochs = 10\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=0.00175)\n",
    "shed = torch.optim.lr_scheduler.CosineAnnealingLR(opt, nepochs*len(train_dataloader))\n",
    "\n",
    "loss_his, train_loss = [], []\n",
    "print(\"16\")\n",
    "best_score = 0.\n",
    "best_state_dict = copy.deepcopy(model.state_dict())\n",
    "print(\"19\")\n",
    "for epoch in range(nepochs):\n",
    "    model.train()\n",
    "    print(\"22\")\n",
    "    for i, (eeg_batch, mask_batch) in enumerate(train_dataloader):\n",
    "        eeg_batch, mask_batch = eeg_batch.to(device), mask_batch.to(device)\n",
    "\n",
    "        logits = model(eeg_batch)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, mask_batch.float())\n",
    "        loss.backward()\n",
    "\n",
    "        opt.step()\n",
    "        shed.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        print(\"35\")\n",
    "    if (epoch + 1) % 25 == 0:\n",
    "        loss_his.append(np.mean(train_loss))\n",
    "        train_loss.clear()\n",
    "\n",
    "        print('[Epoch {}/{}] [Loss: {}]'.format(epoch+1, nepochs, loss_his[-1]))\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        y_pred = []\n",
    "\n",
    "        size = 10000\n",
    "        \n",
    "        for eeg_batch, _ in tqdm(valid_dataloader):\n",
    "            for idx in range((eeg_batch.shape[-1] + size - 1) // size):\n",
    "                with torch.no_grad():\n",
    "                    eeg_batch_ = eeg_batch[:, :, idx*size: (idx+1)*size].to(device)\n",
    "\n",
    "                    logits = model(eeg_batch_)\n",
    "                    probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
    "\n",
    "                    y_pred.append(probs)\n",
    "\n",
    "        y_pred = np.concatenate(y_pred, axis=1).T\n",
    "        y_true = np.concatenate(ys_valid, axis=0)\n",
    "\n",
    "        score = metrics.roc_auc_score(y_true, y_pred)\n",
    "\n",
    "        print('[Epoch {}/{}] [Score: {}]'.format(epoch+1, nepochs, score))\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_state_dict = copy.deepcopy(model.state_dict())\n",
    "    print(\"68\")\n",
    "model.load_state_dict(best_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7600c54",
   "metadata": {
    "papermill": {
     "duration": 0.03499,
     "end_time": "2024-01-18T12:38:14.624607",
     "exception": false,
     "start_time": "2024-01-18T12:38:14.589617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Score on train part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870c4ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T12:38:14.695400Z",
     "iopub.status.busy": "2024-01-18T12:38:14.695007Z",
     "iopub.status.idle": "2024-01-18T12:38:14.702078Z",
     "shell.execute_reply": "2024-01-18T12:38:14.701175Z"
    },
    "papermill": {
     "duration": 0.04495,
     "end_time": "2024-01-18T12:38:14.703920",
     "exception": false,
     "start_time": "2024-01-18T12:38:14.658970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc(y_true, y_pred):\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(15, 13))\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        fpr, tpr, _ = metrics.roc_curve(y_true[i], y_pred[i])\n",
    "        ax = axs[i//2, i%2]\n",
    "        ax.plot(fpr, tpr)\n",
    "        ax.set_title(label + ' ROC')\n",
    "        ax.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d138df7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T12:38:14.774759Z",
     "iopub.status.busy": "2024-01-18T12:38:14.774011Z",
     "iopub.status.idle": "2024-01-18T12:40:11.852586Z",
     "shell.execute_reply": "2024-01-18T12:40:11.851293Z"
    },
    "papermill": {
     "duration": 117.164191,
     "end_time": "2024-01-18T12:40:11.902660",
     "exception": false,
     "start_time": "2024-01-18T12:38:14.738469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "size = 10000\n",
    "\n",
    "for eeg_batch, _ in tqdm(train_dataloader_):\n",
    "    for idx in range((eeg_batch.shape[-1] + size - 1) // size):\n",
    "        with torch.no_grad():\n",
    "            eeg_batch_ = eeg_batch[:, :, idx*size: (idx+1)*size].to(device)\n",
    "\n",
    "            logits = model(eeg_batch_)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
    "\n",
    "            y_pred.append(probs)\n",
    "\n",
    "y_pred = np.concatenate(y_pred, axis=1).T\n",
    "y_true = np.concatenate(ys_train, axis=0)\n",
    "\n",
    "plot_roc(y_true.T, y_pred.T)\n",
    "\n",
    "print('roc auc: ', metrics.roc_auc_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fee69a3",
   "metadata": {
    "papermill": {
     "duration": 0.048205,
     "end_time": "2024-01-18T12:40:11.999935",
     "exception": false,
     "start_time": "2024-01-18T12:40:11.951730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Score on val part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09a572",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T12:40:12.106395Z",
     "iopub.status.busy": "2024-01-18T12:40:12.105056Z",
     "iopub.status.idle": "2024-01-18T12:40:15.119186Z",
     "shell.execute_reply": "2024-01-18T12:40:15.117881Z"
    },
    "papermill": {
     "duration": 3.069321,
     "end_time": "2024-01-18T12:40:15.121189",
     "exception": false,
     "start_time": "2024-01-18T12:40:12.051868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "size = 10000\n",
    "\n",
    "for eeg_batch, _ in tqdm(valid_dataloader):\n",
    "    for idx in range((eeg_batch.shape[-1] + size - 1) // size):\n",
    "        with torch.no_grad():\n",
    "            eeg_batch_ = eeg_batch[:, :, idx*size: (idx+1)*size].to(device)\n",
    "\n",
    "            logits = model(eeg_batch_)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
    "\n",
    "            y_pred.append(probs)\n",
    "\n",
    "y_pred = np.concatenate(y_pred, axis=1).T\n",
    "y_true = np.concatenate(ys_valid, axis=0)\n",
    "\n",
    "plot_roc(y_true.T, y_pred.T)\n",
    "\n",
    "print('roc auc: ', metrics.roc_auc_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0309ef8b",
   "metadata": {
    "papermill": {
     "duration": 0.047166,
     "end_time": "2024-01-18T12:40:15.215459",
     "exception": false,
     "start_time": "2024-01-18T12:40:15.168293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08626792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T12:40:15.315332Z",
     "iopub.status.busy": "2024-01-18T12:40:15.314940Z",
     "iopub.status.idle": "2024-01-18T12:40:27.332256Z",
     "shell.execute_reply": "2024-01-18T12:40:27.331341Z"
    },
    "papermill": {
     "duration": 12.070205,
     "end_time": "2024-01-18T12:40:27.334624",
     "exception": false,
     "start_time": "2024-01-18T12:40:15.264419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "xs_test = []\n",
    "lengths = {}\n",
    "\n",
    "testdir = Path('test')\n",
    "\n",
    "FNAME = 'subj{}_series{}_{}.csv'\n",
    "\n",
    "for subj in range(1, 13):\n",
    "    for series in [9, 10]:\n",
    "        datapath = testdir / FNAME.format(subj, series, 'data')\n",
    "\n",
    "        x = pd.read_csv(datapath)\n",
    "        x = x.iloc[:,1:].values\n",
    "\n",
    "        xs_test.append(x.astype(np.float32))\n",
    "        lengths['{}_{}'.format(subj, series)] = xs_test[-1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916e426f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T12:40:27.429109Z",
     "iopub.status.busy": "2024-01-18T12:40:27.428732Z",
     "iopub.status.idle": "2024-01-18T12:40:27.435052Z",
     "shell.execute_reply": "2024-01-18T12:40:27.434216Z"
    },
    "papermill": {
     "duration": 0.055813,
     "end_time": "2024-01-18T12:40:27.436936",
     "exception": false,
     "start_time": "2024-01-18T12:40:27.381123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EEGDatasetTest(Dataset):\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eeg = self.x[idx]\n",
    "\n",
    "        return eeg.T\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "dataset = EEGDatasetTest(xs_test)\n",
    "test_dataloader = DataLoader(dataset, batch_size=1, num_workers=3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488fe844",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T12:40:27.530881Z",
     "iopub.status.busy": "2024-01-18T12:40:27.530481Z",
     "iopub.status.idle": "2024-01-18T12:40:37.275856Z",
     "shell.execute_reply": "2024-01-18T12:40:37.274708Z"
    },
    "papermill": {
     "duration": 9.795097,
     "end_time": "2024-01-18T12:40:37.278016",
     "exception": false,
     "start_time": "2024-01-18T12:40:27.482919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "size = 10000\n",
    "\n",
    "for eeg_batch in tqdm(test_dataloader):\n",
    "    for idx in range((eeg_batch.shape[-1] + size - 1) // size):\n",
    "        with torch.no_grad():\n",
    "            eeg_batch_ = eeg_batch[:, :, idx*size: (idx+1)*size].to(device)\n",
    "\n",
    "            logits = model(eeg_batch_)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
    "\n",
    "            y_pred.append(probs)\n",
    "\n",
    "y_pred = np.concatenate(y_pred, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b972e959",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T12:40:37.377179Z",
     "iopub.status.busy": "2024-01-18T12:40:37.376291Z",
     "iopub.status.idle": "2024-01-18T12:41:35.554179Z",
     "shell.execute_reply": "2024-01-18T12:41:35.553261Z"
    },
    "papermill": {
     "duration": 58.279961,
     "end_time": "2024-01-18T12:41:35.606515",
     "exception": false,
     "start_time": "2024-01-18T12:40:37.326554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(y_pred, index=['subj{}_series{}_{}'.format(sbj, i, j) for sbj in range(1, 13) for i in [9, 10] for j in range(lengths['{}_{}'.format(sbj, i)])], columns=labels)\n",
    "submission.to_csv('Submission.csv', index_label='id', float_format='%.3f')\n",
    "\n",
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d787f90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T12:41:35.705952Z",
     "iopub.status.busy": "2024-01-18T12:41:35.705009Z",
     "iopub.status.idle": "2024-01-18T12:41:36.727376Z",
     "shell.execute_reply": "2024-01-18T12:41:36.726332Z"
    },
    "papermill": {
     "duration": 1.074214,
     "end_time": "2024-01-18T12:41:36.729596",
     "exception": false,
     "start_time": "2024-01-18T12:41:35.655382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!head Submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b90549",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T12:41:36.829602Z",
     "iopub.status.busy": "2024-01-18T12:41:36.828549Z",
     "iopub.status.idle": "2024-01-18T12:41:37.853855Z",
     "shell.execute_reply": "2024-01-18T12:41:37.852045Z"
    },
    "papermill": {
     "duration": 1.077851,
     "end_time": "2024-01-18T12:41:37.856453",
     "exception": false,
     "start_time": "2024-01-18T12:41:36.778602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!head sample_submission.csv"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 44220,
     "sourceId": 4477,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1751.186703,
   "end_time": "2024-01-18T12:41:40.599702",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-18T12:12:29.412999",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
